{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d10fc4c1-b901-4d46-b4b0-a0c05efdd7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium import Env, spaces, register, make\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9c10ccee-833a-4372-af12-ca81e3c26a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomMazeEnvironment(Env):\n",
    "    def __init__(self):\n",
    "        \n",
    "        # at terminal state, whatever action taken leads to 0 reward and no state transition with  1 probability\n",
    "        # no need to define wall state 5 as agent will never be there\n",
    "        # if action is hitting two boundaries with 0.8, 0.1 percentage occuring, 0.9 precentage chance defined to be in the current state itself.\n",
    "        \n",
    "        self.possibilities = {\n",
    "            0: { #[(transition_prob, next state, reward, termination_status)]\n",
    "                0: [(0.9, 0, -0.04, False), (0.1, 1, -0.04, False)],\n",
    "                1: [(0.8, 1, -0.04, False),(0.1, 4, -0.04, False),(0.1, 0, -0.04, False)],\n",
    "                2: [(0.8, 4, -0.04, False),(0.1, 1, -0.04, False),(0.1, 0, -0.04, False)],\n",
    "                3: [(0.9, 0, -0.04, False), (0.1, 4, -0.04, False)]\n",
    "            },\n",
    "            1: {\n",
    "                0: [(0.8, 1, -0.04, False), (0.1, 2, -0.04, False), (0.1, 0, -0.04, False)],\n",
    "                1: [(0.8, 2, -0.04, False),(0.2, 1, -0.04, False)],\n",
    "                2: [(0.8, 1, -0.04, False), (0.1, 2, -0.04, False), (0.1, 0, -0.04, False)],\n",
    "                3: [(0.8, 0, -0.04, False),(0.2, 1, -0.04, False)]\n",
    "            },\n",
    "            2: {\n",
    "                0: [(0.8, 2, -0.04, False), (0.1, 3, 1.0, True), (0.1, 1, -0.04, False)],\n",
    "                1: [(0.8, 3, 1.0, True),(0.1, 6, -0.04, False),(0.1, 2, -0.04, False)],\n",
    "                2: [(0.8, 6, -0.04, False),(0.1, 3, 1.0, True),(0.1, 1, -0.04, False)],\n",
    "                3: [(0.8, 1, -0.04, False),(0.1, 6, -0.04, False), (0.1, 2, -0.04, False)]\n",
    "            },\n",
    "            3: {\n",
    "                0: [(1.0, 3, 0, True)],\n",
    "                1: [(1.0, 3, 0, True)],\n",
    "                2: [(1.0, 3, 0, True)],\n",
    "                3: [(1.0, 3, 0, True)]\n",
    "            },\n",
    "            4: {\n",
    "                0: [(0.8, 0, -0.04, False),(0.2, 4, -0.04, False)],\n",
    "                1: [(0.8, 4, -0.04, False),(0.1, 8, -0.04, False),(0.1, 0, -0.04, False)],\n",
    "                2: [(0.8, 8, -0.04, False),(0.2, 4, -0.04, False)],\n",
    "                3: [(0.8, 4, -0.04, False),(0.1, 0, -0.04, False), (0.1, 8, -0.04, False)]\n",
    "            },\n",
    "            6: {\n",
    "                0: [(0.8, 2, -0.04, False),(0.1, 7, -1.0, True), (0.1, 6, -0.04, False)],\n",
    "                1: [(0.8, 7, -1.0, True),(0.1, 10, -0.04, False),(0.1, 2, -0.04, False)],\n",
    "                2: [(0.8, 10, -0.04, False),(0.1, 7, -1.0, True), (0.1, 6, -0.04, False)],\n",
    "                3: [(0.8, 6, -0.04, False),(0.1, 10, -0.04, False), (0.1, 2, -0.04, False)]\n",
    "            },\n",
    "            7: {\n",
    "                0: [(1.0, 7, 0, True)],\n",
    "                1: [(1.0, 7, 0, True)],\n",
    "                2: [(1.0, 7, 0, True)],\n",
    "                3: [(1.0, 7, 0, True)]\n",
    "            },\n",
    "            8: {\n",
    "                0: [(0.8, 4, -0.04, False),(0.1, 9, -0.04, False),(0.1, 8, -0.04, False)],\n",
    "                1: [(0.8, 9, -0.04, False),(0.1, 8, -0.04, False),(0.1, 4, -0.04, False)],\n",
    "                2: [(0.9, 8, -0.04, False),(0.1, 9, -0.04, False)],\n",
    "                3: [(0.9, 8, -0.04, False), (0.1, 4, -0.04, False)]\n",
    "            },\n",
    "            9: {\n",
    "                0: [(0.8, 9, -0.04, False),(0.1, 8, -0.04, False),(0.1, 10, -0.04, False)],\n",
    "                1: [(0.8, 10, -0.04, False),(0.2, 9, -0.04, False)],\n",
    "                2: [(0.8, 9, -0.04, False),(0.1, 10, -0.04, False),(0.1, 8, -0.04, False)],\n",
    "                3: [(0.8, 8, -0.04, False),(0.2, 9, -0.04, False)]\n",
    "            },\n",
    "            10: {\n",
    "                0: [(0.8, 6, -0.04, False),(0.1, 9, -0.04, False),(0.1, 11, -0.04, False)],\n",
    "                1: [(0.8, 11, -0.04, False),(0.1, 6, -0.04, False),(0.1, 10, -0.04, False)],\n",
    "                2: [(0.8, 10, -0.04, False),(0.1, 9, -0.04, False),(0.1, 11, -0.04, False)],\n",
    "                3: [(0.8, 9, -0.04, False),(0.1, 6, -0.04, False), (0.1, 10, -0.04, False)]\n",
    "            },\n",
    "            11: {\n",
    "                0: [(0.8, 7, -1.0, True),(0.1, 11, -0.04, False),(0.1, 10, -0.04, False)],\n",
    "                1: [(0.9, 11, -0.04, False),(0.1, 7, -1.0, True)],\n",
    "                2: [(0.9, 11, -0.04, False),(0.1, 10, -0.04, False)],\n",
    "                3: [(0.8, 10, -0.04, False),(0.1, 7, -1.0, True), (0.1, 11, -0.04, False)]\n",
    "            }\n",
    "            \n",
    "        }\n",
    "        # observe: [state, action, nextState, reward]\n",
    "        self.observation_space = spaces.MultiDiscrete([12, 4, 12, 3])\n",
    "            \n",
    "        # up - 0, right - 1, down - 2, left - 3\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        \n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self._agent_location = 8\n",
    "        self._target_location = 3\n",
    "        self._dead_state = 7\n",
    "        self.wall = 5\n",
    "\n",
    "        prev_location = self._agent_location\n",
    "        action = spaces.Discrete(4).sample()\n",
    "        transitions = self.possibilities[prev_location][action]\n",
    "        probabilities, next_states, rewards, terminals = zip(*transitions)\n",
    "\n",
    "        # Randomly select a transition based on the probabilities\n",
    "        index = random.choices(range(len(probabilities)), weights=probabilities, k=1)[0]\n",
    "        self._agent_location, reward, terminated = next_states[index], rewards[index], terminals[index]\n",
    "\n",
    "        observation = [8, action, self._agent_location, reward]\n",
    "        info = {'Start State': 8, 'Action': action, 'Next State': self._agent_location, 'Reward': reward, 'termination_status': terminated}\n",
    "\n",
    "        return observation, info\n",
    "    \n",
    "    def step(self, action):\n",
    "\n",
    "        prev_location = self._agent_location\n",
    "        transitions = self.possibilities[prev_location][action]\n",
    "        probabilities, next_states, rewards, terminals = zip(*transitions)\n",
    "\n",
    "        # Randomly select a transition based on the probabilities\n",
    "        index = random.choices(range(len(probabilities)), weights=probabilities, k=1)[0]\n",
    "        self._agent_location, reward, terminated = next_states[index], rewards[index], terminals[index]\n",
    "\n",
    "        truncated = False\n",
    "        observation = [prev_location, action, self._agent_location, reward]\n",
    "        info = {'Start State': prev_location, 'Action': action, 'Next State': self._agent_location, 'Reward': reward, 'termination_status': terminated}\n",
    "\n",
    "        return observation, reward, terminated, truncated, info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9143df61-eef8-42eb-93ec-7f9bbbaf1036",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Desktop\\CS780_Assignment1\\cs780_env\\lib\\site-packages\\gymnasium\\envs\\registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment RandomMazeEnvironment-mark0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
     ]
    }
   ],
   "source": [
    "register(id = 'RandomMazeEnvironment-mark0', entry_point= RandomMazeEnvironment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b05f9ecf-b499-470d-bde2-20e08b7a05a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make('RandomMazeEnvironment-mark0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "f482ec62-bd34-478a-ad86-785dd9decd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: {'Start State': 8, 'Action': 2, 'Next State': 8, 'Reward': -0.04}, Total Reward: -0.04\n",
      "Step 1: {'Start State': 8, 'Action': 0, 'Next State': 8, 'Reward': -0.04}, Total Reward: -0.08\n",
      "Step 2: {'Start State': 8, 'Action': 0, 'Next State': 4, 'Reward': -0.04}, Total Reward: -0.12\n",
      "Step 3: {'Start State': 4, 'Action': 0, 'Next State': 0, 'Reward': -0.04}, Total Reward: -0.16\n",
      "Step 4: {'Start State': 0, 'Action': 0, 'Next State': 0, 'Reward': -0.04}, Total Reward: -0.2\n",
      "Step 5: {'Start State': 0, 'Action': 0, 'Next State': 0, 'Reward': -0.04}, Total Reward: -0.24000000000000002\n",
      "Episode not completed. Step limit reached. Ending game!\n"
     ]
    }
   ],
   "source": [
    "#tested environment for 5 runs, Step 0 as initializing step\n",
    "\n",
    "observation, info = env.reset(seed = 2)\n",
    "total_reward = info['Reward'] #add all reward for each step\n",
    "print(f'Step 0: {info}, Total Reward: {total_reward}')\n",
    "\n",
    "maxSteps = 5\n",
    "#taking only up as action\n",
    "for j in range(maxSteps):\n",
    "    \n",
    "    action = 0 # always up action\n",
    "    # action = random.choices(range(4))[0] #select a random action\n",
    "    \n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    \n",
    "    print(f'Step {j+1}: {info}, Total Reward: {total_reward}')\n",
    "    \n",
    "    if (terminated == True):\n",
    "        print('Episode Completed. Ending game!')\n",
    "        break\n",
    "    elif (terminated == False and j == maxSteps -1):\n",
    "        truncated == True\n",
    "        print('Episode not completed. Step limit reached. Ending game!')\n",
    "\n",
    "# run the cell for multiple times to see the use of both termination and truncation\n",
    "# since action is set to always be 'up', i.e 0, there comes a chance of ending the game starting from 8 and ending at either at the hole or goal, \n",
    "# with the given transition probabilities. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs780_env",
   "language": "python",
   "name": "cs780_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
